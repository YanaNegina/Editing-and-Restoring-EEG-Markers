{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHBkIBz7EBk0"
      },
      "outputs": [],
      "source": [
        "# Восстановление маркеров на основе данных фотодетектора.\n",
        "\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Имя файла .vhdr\n",
        "vhdr_path = \"Confidence_test000030.vhdr\"  # заменить на нужный файл при необходимости\n",
        "\n",
        "# Загрузка только канала PhotoS\n",
        "raw = mne.io.read_raw_brainvision(vhdr_path, preload=False)\n",
        "raw.pick_channels(['PhotoS'])\n",
        "\n",
        "# Параметры обработки\n",
        "sfreq = raw.info['sfreq']\n",
        "duration_sec = raw.n_times / sfreq\n",
        "chunk_duration = 60  # обработка по 60 секунд\n",
        "threshold = 2.2      # амплитудный порог\n",
        "min_interval_sec = 0.5    # мин интервал -> корректировать в зависимости от RT\n",
        "min_interval_samples = int(min_interval_sec * sfreq)\n",
        "\n",
        "# Детекция событий по частям\n",
        "all_markers = []\n",
        "marker_index = 1\n",
        "\n",
        "for start_time in range(0, int(duration_sec), chunk_duration):\n",
        "    end_time = min(start_time + chunk_duration, duration_sec)\n",
        "    start_sample = int(start_time * sfreq)\n",
        "    end_sample = int(end_time * sfreq)\n",
        "\n",
        "    try:\n",
        "        segment, times = raw[:, start_sample:end_sample]\n",
        "        signal = segment[0]\n",
        "\n",
        "        last_index = -min_interval_samples\n",
        "        for i in range(1, len(signal)):\n",
        "            if signal[i - 1] < threshold and signal[i] >= threshold:\n",
        "                if i - last_index >= min_interval_samples:\n",
        "                    all_markers.append((times[i], marker_index))\n",
        "                    marker_index += 1\n",
        "                    last_index = i\n",
        "    except:\n",
        "        print(f\"Пропущен фрагмент {start_time}–{end_time}\")\n",
        "        continue\n",
        "\n",
        "# Сохраняем результат\n",
        "df = pd.DataFrame(all_markers, columns=[\"onset_sec\", \"marker_code\"])\n",
        "df.to_csv(\"photo_markers.csv\", index=False)\n",
        "files.download(\"photo_markers.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Восстановление маркеров уверенности на основании файла с поведенческими данными\n",
        "\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import re\n",
        "\n",
        "def process_type2_markers(vmrk_in: str, base_report_csv: str, vmrk_out: str):\n",
        "    # 1) Чтение header + Mk строк\n",
        "    header_lines, raw_marker_lines = [], []\n",
        "    in_marker_section = False\n",
        "\n",
        "    with open(vmrk_in, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            stripped = line.rstrip('\\n')\n",
        "            if stripped.strip() == '[Marker Infos]':\n",
        "                in_marker_section = True\n",
        "                header_lines.append(stripped)\n",
        "                continue\n",
        "\n",
        "            if not in_marker_section:\n",
        "                header_lines.append(stripped)\n",
        "            else:\n",
        "                if stripped.startswith('Mk'):\n",
        "                    raw_marker_lines.append(stripped)\n",
        "                else:\n",
        "                    header_lines.append(stripped)\n",
        "\n",
        "    # удаление пропусков\n",
        "    while header_lines and header_lines[-1].strip() == \"\":\n",
        "        header_lines.pop()\n",
        "\n",
        "    # 2) Парсинг Mk строк\n",
        "    markers = []\n",
        "    for mk in raw_marker_lines:\n",
        "        _, rest = mk.split('=', 1)\n",
        "        parts = rest.split(',')\n",
        "        clean = parts[1].replace(' ', '')\n",
        "        latency = int(parts[2])\n",
        "        markers.append({'parts': parts, 'latency': latency, 'clean': clean})\n",
        "\n",
        "    # 3) Загрузка BaseReport CSV (автодетекция , vs ;)\n",
        "    with open(base_report_csv, 'r', encoding='utf-8', errors='replace') as f:\n",
        "        first = f.readline()\n",
        "    sep = ',' if ',' in first else ';'\n",
        "    df = pd.read_csv(base_report_csv, sep=sep, encoding='utf-8', engine='python')\n",
        "    df.columns = df.columns.str.strip().str.lstrip('\\ufeff')\n",
        "    conf_col = next(c for c in df.columns if 'Увер' in c)\n",
        "    conf = df[conf_col].astype(int)\n",
        "\n",
        "    # 4) Добавление S 6/S 7 посередине S 4/5 и следующего S 1\n",
        "    injected = []\n",
        "    s45_idxs = [i for i, m in enumerate(markers) if m['clean'] in ('S4','S5')]\n",
        "    for trial_idx, idx45 in enumerate(s45_idxs):\n",
        "        lat45 = markers[idx45]['latency']\n",
        "        # поиск S 1\n",
        "        s1s = [m['latency'] for m in markers if m['latency'] > lat45 and m['clean']=='S1']\n",
        "        if s1s:\n",
        "            midpoint = lat45 + (min(s1s) - lat45)//2\n",
        "        else:\n",
        "            midpoint = lat45 + 500  # 500 ms после последней S4/5\n",
        "\n",
        "        label = f\"S  {6 if conf.iloc[trial_idx] == 1 else 7}\"\n",
        "        injected.append({'parts': ['Stimulus', label, str(midpoint), '1', '0'], 'latency': midpoint})\n",
        "\n",
        "    # 5) Объединение и сортировка\n",
        "    all_entries = markers + injected\n",
        "    all_entries.sort(key=lambda x: x['latency'])\n",
        "\n",
        "    # 6) Новый .vmrk\n",
        "    with open(vmrk_out, 'w', encoding='utf-8') as f:\n",
        "        for line in header_lines:\n",
        "            f.write(line + \"\\n\")\n",
        "        for i, ent in enumerate(all_entries, 1):\n",
        "            f.write(f\"Mk{i}=\" + \",\".join(ent['parts']) + \"\\n\")\n",
        "\n",
        "    print(f\"New Type 2 VMRK: {os.path.basename(vmrk_out)}\")\n",
        "\n",
        "def find_base_report(recording_num: str) -> str:\n",
        "    # Поиск подходящего BaseReport по названию\n",
        "    pattern = f\"BaseReport_{recording_num}_*CORR*.csv\"\n",
        "    matches = glob.glob(pattern)\n",
        "    if not matches:\n",
        "        raise FileNotFoundError(f\"No BaseReport CSV found for recording {recording_num}\")\n",
        "    if len(matches) > 1:\n",
        "        raise FileExistsError(f\"Multiple BaseReport CSVs found for recording {recording_num}: {matches}\")\n",
        "    return matches[0]\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Обработка всех .vmrk в директории\n",
        "    for vmrk_path in glob.glob(\"*.vmrk\"):\n",
        "        # пропуск, если уже есть суффикс\n",
        "        if vmrk_path.endswith(\"_ConfMarkers.vmrk\"):\n",
        "            continue\n",
        "\n",
        "        # Извлечение номера записи, удаляя нули\n",
        "        match = re.search(r\"(\\d+)\", vmrk_path)\n",
        "        if not match:\n",
        "            print(f\"Skipping {vmrk_path}: no recording number found.\")\n",
        "            continue\n",
        "        rec_raw = match.group(1)\n",
        "        try:\n",
        "            rec_num = str(int(rec_raw))  # удаление нулей\n",
        "        except ValueError:\n",
        "            print(f\"Skipping {vmrk_path}: invalid recording number {rec_raw}.\")\n",
        "            continue\n",
        "        try:\n",
        "            base_csv = find_base_report(rec_num)\n",
        "        except (FileNotFoundError, FileExistsError) as e:\n",
        "            print(f\"Skipping {vmrk_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        vmrk_out = vmrk_path.replace('.vmrk', '_ConfMarkers.vmrk')\n",
        "        process_type2_markers(vmrk_path, base_csv, vmrk_out)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "WiShUpUiEgBc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Изменение маркера S 1 на основании маркеров правильности и уверенности.\n",
        "\n",
        "import re\n",
        "import os\n",
        "import glob\n",
        "\n",
        "def process_type1_preserve(vmrk_in, vmrk_out):\n",
        "    # 1) Чтение header + маркеров\n",
        "    header_lines = []\n",
        "    raw_marker_lines = []\n",
        "    in_marker_section = False\n",
        "\n",
        "    with open(vmrk_in, encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            if line.strip() == '[Marker Infos]':\n",
        "                in_marker_section = True\n",
        "                header_lines.append(line.rstrip('\\n'))\n",
        "                continue\n",
        "\n",
        "            if not in_marker_section:\n",
        "                header_lines.append(line.rstrip('\\n'))\n",
        "            else:\n",
        "                # только строки Mk\n",
        "                if line.startswith('Mk'):\n",
        "                    raw_marker_lines.append(line.rstrip('\\n'))\n",
        "                else:\n",
        "                    header_lines.append(line.rstrip('\\n'))\n",
        "\n",
        "    # 2) Парсинг Mk строк в словарь\n",
        "    markers = []\n",
        "    for idx, line in enumerate(raw_marker_lines):\n",
        "        prefix, rest = line.split('=', 1)\n",
        "        parts = rest.split(',')\n",
        "        clean_label = parts[1].replace(' ', '')\n",
        "        latency = int(parts[2])\n",
        "        markers.append({\n",
        "            'idx': idx,\n",
        "            'prefix': prefix,\n",
        "            'parts': parts,\n",
        "            'clean': clean_label,\n",
        "            'latency': latency\n",
        "        })\n",
        "\n",
        "    # 3) Комбинации правильности и уверенности для S1\n",
        "    combo_map = {\n",
        "        ('S4','S6'): '11',\n",
        "        ('S5','S6'): '12',\n",
        "        ('S4','S7'): '13',\n",
        "        ('S5','S7'): '14',\n",
        "    }\n",
        "    replacements = {}\n",
        "    for m in markers:\n",
        "        if m['clean'] == 'S1':\n",
        "            # следующий маркер точности\n",
        "            acc = next((x for x in markers if x['latency'] > m['latency'] and x['clean'] in ('S4','S5')), None)\n",
        "            # следующий маркер уверенности\n",
        "            conf = next((x for x in markers if x['latency'] > m['latency'] and x['clean'] in ('S6','S7')), None)\n",
        "            if acc and conf:\n",
        "                replacements[m['idx']] = combo_map[(acc['clean'], conf['clean'])]\n",
        "\n",
        "    # 4) Переписывание только S1 маркеров\n",
        "    out_marker_lines = []\n",
        "    for idx, m in enumerate(markers):\n",
        "        parts = m['parts']\n",
        "        if idx in replacements:\n",
        "            parts[1] = f\"S {replacements[idx]}\"\n",
        "        out_marker_lines.append(f\"{m['prefix']}=\" + \",\".join(parts))\n",
        "\n",
        "    # 5) Возвращение header и обновленных маркеров\n",
        "    # удаление лишних пробелов\n",
        "    while header_lines and header_lines[-1].strip() == \"\":\n",
        "        header_lines.pop()\n",
        "\n",
        "    with open(vmrk_out, 'w', encoding='utf-8') as f:\n",
        "        for l in header_lines:\n",
        "            f.write(l + \"\\n\")\n",
        "        for l in out_marker_lines:\n",
        "            f.write(l + \"\\n\")\n",
        "\n",
        "    print(f\"Processed: {vmrk_in} -> {vmrk_out}\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Обработка всех .vmrk файлов в директории\n",
        "    pattern = '*.vmrk'\n",
        "    for vmrk_in in glob.glob(pattern):\n",
        "        # пропуск файлов уже с суффиксом\n",
        "        if vmrk_in.endswith('_NewMarkers.vmrk'):\n",
        "            continue\n",
        "        base, ext = os.path.splitext(vmrk_in)\n",
        "        vmrk_out = f\"{base}_NewMarkers{ext}\"\n",
        "        process_type1_preserve(vmrk_in, vmrk_out)"
      ],
      "metadata": {
        "id": "8ieCG7jHEn7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование файлов .vmrk в файлы .Markers для импорта в BrainVision Analyzer.\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# настройки\n",
        "input_dir = \"\"  # папка с файлами .vmrk\n",
        "sampling_rate = 1000      # в Hz\n",
        "sampling_interval = 1     # в ms\n",
        "\n",
        "# программа\n",
        "for vmrk_path in glob.glob(os.path.join(input_dir, \"*.vmrk\")):\n",
        "    basename = os.path.splitext(os.path.basename(vmrk_path))[0]\n",
        "    out_fname = f\"{basename}_Raw Data.Markers\"\n",
        "    out_path = os.path.join(input_dir, out_fname)\n",
        "\n",
        "    with open(vmrk_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    # нахождение начала раздела [Marker Infos]\n",
        "    try:\n",
        "        mi_idx = lines.index(\"[Marker Infos]\\n\")\n",
        "    except ValueError:\n",
        "        print(f\"Skipping {vmrk_path}: no [Marker Infos] section found.\")\n",
        "        continue\n",
        "\n",
        "    # всё после [Marker Infos] - это маркеры\n",
        "    markers = []\n",
        "    for line in lines[mi_idx+1:]:\n",
        "        line = line.strip()\n",
        "        if not line or line.startswith(\";\"):\n",
        "            continue\n",
        "        if not line.startswith(\"Mk\"):\n",
        "            continue\n",
        "\n",
        "        # разделение данных\n",
        "        _, data = line.split(\"=\", 1)\n",
        "        parts = data.split(\",\", 5)\n",
        "        # части: [Type, Description, Position, Length, Channel, (extra if present)]\n",
        "        if parts[0].lower() == \"new segment\":\n",
        "            # пропуск системной строки \"Mk1=New Segment\"\n",
        "            continue\n",
        "\n",
        "        typ         = parts[0]\n",
        "        desc        = parts[1].replace(\"\\\\1\", \",\")\n",
        "        position    = parts[2]\n",
        "        length      = parts[3] if len(parts) > 3 else \"\"\n",
        "        channel_num = parts[4] if len(parts) > 4 else \"0\"\n",
        "\n",
        "        channel = \"All\" if channel_num == \"0\" else channel_num\n",
        "        markers.append(f\"{typ},{desc},{position},{length},{channel}\")\n",
        "\n",
        "    # Создание файла .Markers\n",
        "    with open(out_path, \"w\", encoding=\"utf-8\") as out:\n",
        "        out.write(f\"Sampling rate: {sampling_rate}Hz, SamplingInterval: {sampling_interval}ms\\n\")\n",
        "        out.write(\"Type, Description, Position, Length, Channel\\n\")\n",
        "        for m in markers:\n",
        "            out.write(m + \"\\n\")\n",
        "\n",
        "    print(f\"Written: {out_path}\")"
      ],
      "metadata": {
        "id": "mO_SSRe8Ex_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Изменение маркеров S 2 и S 3 в соответствии с маркером S 1 для файлов .Markers.\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "\n",
        "def process_three_stages(markers_in, markers_out):\n",
        "    # Чтение строк\n",
        "    with open(markers_in, 'r', encoding='utf-8') as f:\n",
        "        lines = [line.rstrip('\\n') for line in f]\n",
        "\n",
        "    # Разделение header и маркеров\n",
        "    # Первые 2 ряда системные\n",
        "    header_lines = lines[:2]\n",
        "    marker_lines = lines[2:]\n",
        "\n",
        "    # Парсинг маркеров в словари\n",
        "    records = []\n",
        "    for line in marker_lines:\n",
        "        if not line.strip():\n",
        "            continue\n",
        "        parts = line.split(',')  # ['Stimulus', 'S  2', '38131', '1', 'All']\n",
        "        clean = parts[1].replace(' ', '')  # 'S2'\n",
        "        records.append({'parts': parts, 'clean': clean})\n",
        "\n",
        "    # Поиск индексов S11-S14\n",
        "    group_idxs = [i for i, r in enumerate(records) if r['clean'] in ('S11','S12','S13','S14')]\n",
        "\n",
        "    # Обработка по сегментам\n",
        "    for idx_num, start in enumerate(group_idxs):\n",
        "        end = group_idxs[idx_num+1] if idx_num+1 < len(group_idxs) else len(records)\n",
        "        group_label = records[start]['clean']  # e.g. 'S11'\n",
        "        suffix = group_label[-1]  # '1', '2', '3', or '4'\n",
        "        for r in records[start+1:end]:\n",
        "            if r['clean'] == 'S2':\n",
        "                # Меняем на 2X\n",
        "                r['parts'][1] = f\"S {2}{suffix}\"\n",
        "            elif r['clean'] == 'S3':\n",
        "                # Меняем на S3X\n",
        "                r['parts'][1] = f\"S {3}{suffix}\"\n",
        "\n",
        "    # Преобразование строк\n",
        "    out_marker_lines = [','.join(r['parts']) for r in records]\n",
        "\n",
        "    # Вывод\n",
        "    with open(markers_out, 'w', encoding='utf-8') as f:\n",
        "        for line in header_lines:\n",
        "            f.write(line + '\\n')\n",
        "        for line in out_marker_lines:\n",
        "            f.write(line + '\\n')\n",
        "\n",
        "    print(f\"Processed: {markers_in} -> {markers_out}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Директория для вывода\n",
        "    out_dir = 'three_stages'\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # Обработка всех файлов .Markers в директории\n",
        "    for infile in glob.glob('*.Markers'):\n",
        "        if infile.endswith('_three_stages.Markers'):\n",
        "            continue\n",
        "        base, ext = os.path.splitext(infile)\n",
        "        outfile = os.path.join(out_dir, f\"{base}_three_stages{ext}\")\n",
        "        process_three_stages(infile, outfile)"
      ],
      "metadata": {
        "id": "aAsIE0E2E17s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}